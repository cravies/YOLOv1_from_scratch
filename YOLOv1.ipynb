{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nvdb58cfONaD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageTransform\n",
    "import random as rand\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import copy\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make torch dataset with YOLO labels\n",
    "We have a simple dataset with images and bounding boxes for four \n",
    "types of animal:\n",
    "* buffalo\n",
    "* elephant\n",
    "* rhino\n",
    "* zebra\n",
    "<br>\n",
    "In our instance, YOLO has the following format:\n",
    "output [x1,y1,w1,h1,C1,p11,p12,p13,p14,x2,y2,w2,h2,C2,p21,p22,p23,p24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions for creating labels\n",
    "\n",
    "PATH='/Users/ben/Downloads/archive'\n",
    "\n",
    "def wide_or_tall(bbox):\n",
    "    # wide or tall bbox\n",
    "    x1 = bbox[0]\n",
    "    y1 = bbox[1]\n",
    "    x2 = bbox[2]\n",
    "    y2 = bbox[3]\n",
    "    if abs(x1-x2)>abs(y1-y2):\n",
    "        return 'wide'\n",
    "    else:\n",
    "        return 'tall'\n",
    "\n",
    "def probs(classname):\n",
    "    #return C,p1,p2,p3,p4 subarr given object exists\n",
    "    if classname=='buffalo':\n",
    "        return [1,1,0,0,0]\n",
    "    elif classname=='elephant':\n",
    "        return [1,0,1,0,0]\n",
    "    elif classname=='rhino':\n",
    "        return [1,0,0,1,0]\n",
    "    elif classname==\"zebra\":\n",
    "        return [1,0,0,0,1]\n",
    "    else:\n",
    "        raise ValueError(\"Class name invalid: \",classname)\n",
    "\n",
    "# now we make our labels in [x1,y1,w1,h1,C1,p11,p12,p13,p14,x2,y2,w2,h2,C2,p21,p22,p23,p24] format\n",
    "# say first bbox prediction wide, second bbox prediction tall\n",
    "\n",
    "def make_labels(path):\n",
    "    #read dataset labels into dictionary\n",
    "    labels={}\n",
    "    os.chdir(path)\n",
    "    animals=['buffalo','elephant','rhino','zebra']\n",
    "    for i,animal in enumerate(animals):\n",
    "        for file in os.listdir(f'{path}/{animal}'):\n",
    "            if '.txt' in file:\n",
    "                classname = i\n",
    "                f = open(f'{animal}/{file}')\n",
    "                label = f.readlines()\n",
    "                label = [l.replace('\\n','') for l in label][0].split(' ')\n",
    "                label = [float(l) for l in label]\n",
    "                bbox = label[1:]\n",
    "                bbox_type = wide_or_tall(bbox)\n",
    "                if bbox_type=='wide':\n",
    "                    result_left = np.concatenate([bbox,probs(animal)])\n",
    "                    result = np.concatenate([result_left,np.zeros([9,])])\n",
    "                elif bbox_type=='tall':\n",
    "                    result_right = np.concatenate([bbox,probs(animal)])\n",
    "                    result = np.concatenate([np.zeros([9,]),result_right])\n",
    "                labels[f'{animal}/{file}']=result\n",
    "    return labels\n",
    "\n",
    "labels = make_labels(PATH)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make our own torch dataset type...\n",
    "# as we have custom labels\n",
    "# inherits torch.utils.data.Dataset\n",
    "class YOLODataset(Dataset):\n",
    "    \"\"\"YOLO dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path=PATH, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path: path to the dataset root folder, \n",
    "            default set by global var\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.labels = make_labels(self.path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        fname = list(self.labels.keys())[idx]\n",
    "        \n",
    "        label = self.labels[fname]\n",
    "        img_name=f\"{self.path}/{fname}\"\n",
    "        img_name=img_name.replace('.txt','.jpg')\n",
    "        with Image.open(img_name) as im:\n",
    "            im = np.asarray(im)\n",
    "            shape = im.shape\n",
    "            #gotta reshape h,w,c -> c,h,w for torch\n",
    "            im = im.reshape([3,shape[0],shape[1]])\n",
    "            sample = {'image': np.asarray(im), 'label': label}\n",
    "        return sample\n",
    "    \n",
    "    def __showbbox__(self,idx):\n",
    "        # return image with drawn bbox\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        res = self.__getitem__(idx)\n",
    "        img = res['image']\n",
    "        label = res['label']\n",
    "        # wide bbox on left, tall on right\n",
    "        widebbox = label[0:9]\n",
    "        tallbbox = label[9:]\n",
    "        if(widebbox.sum()!=0):\n",
    "            print(widebbox)\n",
    "        else:\n",
    "            print(tallbbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = YOLODataset()\n",
    "print(ds.__len__())\n",
    "print(ds.__getitem__(200)['image'].shape)\n",
    "ds.__showbbox__(200)\n",
    "# need to write custom collate function to prevent \n",
    "# torch stacking different size input images\n",
    "train_dataloader = DataLoader(ds, batch_size=1,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RjB8zMkOBGg"
   },
   "outputs": [],
   "source": [
    "# Get gpu device for training if available otherwise use cpu\n",
    "device = \"mps\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# darknet conv function adapted from Darknet53 implementation\n",
    "# https://github.com/developer0hye/PyTorch-Darknet53/blob/master/model.py\n",
    "\n",
    "def dark_conv(c_in, c_out, kernel=1, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Construct a convolutional block function \n",
    "    given the input dimensions\n",
    "    c_in: channels in\n",
    "    c_out: channels out\n",
    "    kernel: filter / convolution size (is square)\n",
    "    stride: convolution stride \n",
    "    padding: convolution padding \n",
    "\n",
    "    Based on DarkNet19 configuration\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, kernel, stride, padding),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU())\n",
    "\n",
    "# Our CNN model\n",
    "class DarkNet19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DarkNet19, self).__init__()\n",
    "        self.c1 = dark_conv(3, 32, 3)\n",
    "        self.c2 = dark_conv(32, 64, 3)\n",
    "        self.c3 = dark_conv(64, 128, 3)\n",
    "        self.c4 = dark_conv(128, 64, 1)\n",
    "        self.c5 = dark_conv(64, 128, 3)\n",
    "        self.c6 = dark_conv(128, 256, 3)\n",
    "        self.c7 = dark_conv(256, 128, 1)\n",
    "        self.c8 = dark_conv(128, 256, 3)\n",
    "        self.c9 = dark_conv(256, 512, 3)\n",
    "        self.c10 = dark_conv(512, 256, 1)\n",
    "        self.c11 = dark_conv(256, 512, 3)\n",
    "        self.c12 = dark_conv(512, 256, 1)\n",
    "        self.c13 = dark_conv(256, 512, 3)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # output [x1,y1,w1,h1,C1,p11,p12,p13,p14,x2,y2,w2,h2,C2,p21,p22,p23,p24]\n",
    "        self.fc = nn.Linear(512,18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # feature extraction\n",
    "        x = self.c1(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = self.c2(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = self.c3(x)\n",
    "        x = self.c4(x)\n",
    "        x = self.c5(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = self.c6(x)\n",
    "        x = self.c7(x)\n",
    "        x = self.c8(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = self.c9(x)\n",
    "        x = self.c10(x)\n",
    "        x = self.c11(x)\n",
    "        x = self.c12(x)\n",
    "        x = self.c13(x)\n",
    "        # head\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(-1, 512)\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "#declare CNN model instance\n",
    "model = DarkNet19().to(device)\n",
    "print(\"Neural Network PyTorch Architecture:\")\n",
    "print(model)\n",
    "\n",
    "#define loss function and optimizer\n",
    "#MSE loss for now until we define actual YOLO loss\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkI3d4DVObGr"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Function to train CNN model\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    history = []\n",
    "    total_correct = 0\n",
    "    total_done = 0\n",
    "    count = 0\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        image = torch.tensor(data['image'])\n",
    "        #remove alpha channel\n",
    "        image = image.to(torch.float32).to(device)\n",
    "        label = torch.tensor(data['label'])\n",
    "        label = label.to(torch.float32).to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, label)\n",
    "        print(preds,label)\n",
    "\n",
    "        # Backpropagation block\n",
    "        # reset gradients to zero because by default we accumulate gradient \n",
    "        optimizer.zero_grad()\n",
    "        # compute gradient of loss function using backprop\n",
    "        loss.backward()\n",
    "        # update parameters based on calculated gradient\n",
    "        optimizer.step()\n",
    "\n",
    "    #average accuracy over training set during training\n",
    "    acc = total_correct / total_done\n",
    "    return acc, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsKIZBOf7v0I"
   },
   "source": [
    "Train and plot guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRYIw9_YUGaj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the model\n",
    "Store training and validation loss and accuracy along the way\n",
    "Interrupt when you see the validation accuracy plataeu \n",
    "We then load the best model weights (by validation accuracy)\n",
    "and we can run inference with them\n",
    "\"\"\"\n",
    "#load best previous model\n",
    "try:\n",
    "    model = torch.load('best-model.pt')\n",
    "except:\n",
    "    print(\"No previous model.\")\n",
    "\n",
    "#train\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    t_acc, t_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    print(f\"acc: {t_acc} loss: {t_loss}\")\n",
    "    train_accs.append(t_acc)\n",
    "    train_losses.append(t_loss)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
